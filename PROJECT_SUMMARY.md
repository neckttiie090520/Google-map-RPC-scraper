# Google Maps RPC Scraper - Project Summary

**Version:** 1.0.0
**Status:** Production Ready
**Last Updated:** November 11, 2025
**Author:** Nextzus

---

## ğŸ“Œ Executive Summary

Google Maps RPC Scraper is a production-ready, high-performance web scraping framework for extracting Google Maps reviews and place data without requiring API keys. Built with Python and Flask, it achieves 26-40+ reviews/second with comprehensive anti-bot protection and real-time progress tracking through a modern web interface.

---

## ğŸ¯ Project Goals

### Primary Objectives
1. **No API Key Required** - Use Google's internal RPC API endpoints
2. **High Performance** - Achieve 26-40+ reviews/second in production
3. **Complete Data Extraction** - Extract all 12 review fields (100% coverage)
4. **Anti-Bot Protection** - Avoid detection with sophisticated techniques
5. **User-Friendly Interface** - Provide modern web UI with real-time updates

### Target Users
- **Data Analysts** - Extract review data for analysis
- **Researchers** - Study location-based social behavior
- **Business Owners** - Monitor competitor reviews and sentiment
- **Developers** - Build applications using review data
- **Students** - Learn web scraping and data extraction

---

## ğŸ—ï¸ Technical Architecture

### Technology Stack

**Backend:**
- **Python 3.8+** - Core programming language
- **Flask** - Web application framework
- **httpx** - Async HTTP client for API requests
- **asyncio** - Asynchronous programming

**Frontend:**
- **HTML5/CSS3** - Modern web interface
- **Tailwind CSS** - Utility-first CSS framework
- **JavaScript (Vanilla)** - Client-side interactivity
- **Server-Sent Events (SSE)** - Real-time progress updates

**Data Processing:**
- **JSON/CSV** - Export formats
- **UTF-8 Encoding** - Full Thai/Unicode support

### Core Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Web Application                        â”‚
â”‚  (Flask + SSE + Real-time Progress Tracking)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              RPC Place Search                            â”‚
â”‚  (Find places without API key, get total_reviews)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Production Scraper Engine                       â”‚
â”‚  â€¢ HTTP-only RPC method (no browser overhead)           â”‚
â”‚  â€¢ Page token pagination (zero duplicates)              â”‚
â”‚  â€¢ 3-tier date parsing fallback                         â”‚
â”‚  â€¢ Smart date range filtering                           â”‚
â”‚  â€¢ Progress callbacks                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Anti-Bot Protection Layer                       â”‚
â”‚  â€¢ User-Agent rotation (12+ variants)                   â”‚
â”‚  â€¢ Header randomization                                 â”‚
â”‚  â€¢ Rate limiting detection                              â”‚
â”‚  â€¢ Exponential backoff retry logic                      â”‚
â”‚  â€¢ Proxy rotation (optional)                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Output Management                             â”‚
â”‚  â€¢ Organized directory structure                        â”‚
â”‚  â€¢ JSON + CSV export                                    â”‚
â”‚  â€¢ Metadata generation                                  â”‚
â”‚  â€¢ UTF-8 encoding support                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Key Features Implemented

### 1. Core Scraping Engine
- âœ… **RPC API Method** - Direct HTTP requests to Google's internal API
- âœ… **Page Token Pagination** - Zero-duplicate review extraction
- âœ… **100% Field Extraction** - All 12 review fields captured
- âœ… **3-Tier Date Parsing** - Robust date extraction with fallbacks
- âœ… **Performance** - 26-40+ reviews/second in fast mode

### 2. Anti-Bot Protection
- âœ… **User-Agent Rotation** - 12+ realistic browser signatures
- âœ… **Header Randomization** - Unique fingerprint per request
- âœ… **Rate Limiting** - Auto-slowdown with 60-second rolling window
- âœ… **Retry Logic** - Exponential backoff for 429, 5xx, timeouts
- âœ… **Proxy Support** - HTTP/SOCKS5 rotation (optional)

### 3. Web Application
- âœ… **Modern UI** - Clean, responsive Thai/English interface
- âœ… **Real-Time Progress** - SSE streaming with live updates
- âœ… **Place Search** - RPC-based search without API key
- âœ… **Progress Bars** - Visual feedback showing reviews/max
- âœ… **Multi-Format Export** - Download as JSON or CSV
- âœ… **Unlimited Mode** - Auto-detect total reviews from place data

### 4. Data Quality
- âœ… **Zero Duplicates** - Page token-based pagination
- âœ… **Date Range Filtering** - Smart cutoff detection
- âœ… **Multi-Language** - Thai, English, Japanese, Chinese support
- âœ… **UTF-8 Encoding** - Full Unicode character support
- âœ… **Organized Output** - Timestamped directory structure

---

## ğŸ“Š Performance Metrics

### Speed Benchmarks

| Mode | Delays | Rate | Use Case |
|------|--------|------|----------|
| **Fast Mode** | 50-150ms | 26-40+ reviews/sec | Production scraping |
| **Human Mode** | 500-1500ms | ~10 reviews/sec | Ultra-safe mode |
| **Conservative** | Custom | 3-5 reviews/sec | Maximum stealth |

### Real-World Performance
- **Central World Bangkok** (1000+ reviews): 50 reviews in ~2 seconds
- **Khao Soi Nimman** (500+ reviews): 100 reviews in ~3-4 seconds
- **Zero duplicates** achieved through page token pagination
- **Rate limit handling** with automatic slowdown

---

## ğŸ—‚ï¸ Project Structure

### Directory Organization

```
google-maps-scraper-python/
â”œâ”€â”€ src/                              # Core source code
â”‚   â”œâ”€â”€ scraper/
â”‚   â”‚   â”œâ”€â”€ production_scraper.py    # Main scraping engine (1000+ lines)
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ search/
â”‚   â”‚   â”œâ”€â”€ rpc_place_search.py      # RPC place search
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ anti_bot_utils.py        # Anti-detection utilities
â”‚       â”œâ”€â”€ output_manager.py        # File organization
â”‚       â”œâ”€â”€ unicode_display.py       # Thai/Unicode handling
â”‚       â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ webapp/                           # Web application
â”‚   â”œâ”€â”€ app.py                       # Flask server (700+ lines)
â”‚   â”œâ”€â”€ templates/                   # HTML templates
â”‚   â”‚   â”œâ”€â”€ base.html               # Base layout with Tailwind CSS
â”‚   â”‚   â”œâ”€â”€ index.html              # Home page with search
â”‚   â”‚   â”œâ”€â”€ tasks.html              # Task monitoring with SSE
â”‚   â”‚   â””â”€â”€ results.html            # Results viewer
â”‚   â””â”€â”€ static/                      # CSS, JS, images
â”‚
â”œâ”€â”€ outputs/                          # Scraped data (gitignored)
â”‚   â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ _unused/                          # Archived files
â”‚   â”œâ”€â”€ test_files_20251111/        # Test scripts (30+ files)
â”‚   â”œâ”€â”€ old_docs_20251111/          # Old documentation
â”‚   â””â”€â”€ old_files_20251110/         # Backup scraper versions
â”‚
â”œâ”€â”€ test_scraper.py                  # Quick test script
â”œâ”€â”€ requirements.txt                 # Python dependencies
â”œâ”€â”€ .env                             # Configuration (gitignored)
â”œâ”€â”€ .env.example                     # Configuration template
â”œâ”€â”€ .gitignore                       # Git ignore rules
â”‚
â”œâ”€â”€ README.md                        # Main documentation (560+ lines)
â”œâ”€â”€ CLAUDE.md                        # Developer documentation (1000+ lines)
â”œâ”€â”€ CONTRIBUTING.md                  # Contribution guidelines
â”œâ”€â”€ PROJECT_SUMMARY.md               # This file
â””â”€â”€ LICENSE                          # MIT License
```

### File Statistics
- **Total Source Files**: 15+ Python modules
- **Total Documentation**: 2500+ lines
- **Test Files Archived**: 30+ files
- **Web Templates**: 8+ HTML files

---

## ğŸ”§ Configuration Options

### Environment Variables

```bash
# Language & Region
LANGUAGE_REGION=th                    # th, en, ja, zh

# Scraping
DEFAULT_MAX_REVIEWS=2000              # 0 = unlimited
DEFAULT_DATE_RANGE=1year              # 1month, 6months, 1year, 5years, all

# Performance
FAST_MODE=true                        # true/false
MAX_RATE=10.0                         # requests/second
TIMEOUT=30.0                          # seconds
MAX_RETRIES=3                         # retry attempts

# Anti-Bot
USE_PROXY=false                       # true/false
PROXY_LIST=                           # comma-separated URLs

# Output
AUTO_SAVE=true                        # true/false
DEFAULT_EXPORT=both                   # json, csv, both
```

---

## ğŸ“ˆ Development History

### Evolution Timeline

**2025-11-10 14:00-15:30** - Project 005 Development
- Initial browser-based scraper (4-5 reviews/sec)
- Migrated to HTTP-only RPC (23 reviews/sec, +4.6x)
- Added anti-bot protection (37.83 reviews/sec, +7.5x)
- Implemented 3-tier date parsing
- Achieved zero duplicates with page tokens

**2025-11-10 20:00-23:00** - Framework Integration
- Created modular src/ structure
- Integrated production scraper features
- Built Flask web application
- Added real-time SSE progress tracking

**2025-11-11 00:00-03:00** - Web UI Enhancement
- Designed modern Tailwind CSS interface
- Implemented RPC place search
- Added task management system
- Created results viewer with export

**2025-11-11 03:00-05:00** - Feature Completion
- Added unlimited mode with auto-detection
- Implemented progress callbacks
- Enhanced progress bars with live stats
- Fixed UTF-8 encoding for Thai language
- Optimized performance to 26-30 reviews/sec

**2025-11-11 05:00** - Production Preparation
- Cleaned up project structure
- Moved 30+ test files to _unused/
- Created comprehensive documentation
- Added LICENSE, CONTRIBUTING.md
- Prepared for GitHub release

---

## ğŸ“ Technical Achievements

### 1. RPC API Reverse Engineering
- Successfully reverse-engineered Google Maps internal RPC API
- No API key required - uses pb (Protocol Buffer) parameters
- Handles response format: `)]}'` prefix + JSON
- Extracts page tokens for proper pagination

### 2. Anti-Bot Evasion
- **User-Agent Rotation**: 12+ realistic browser signatures
- **Request Fingerprinting**: Randomized headers per request
- **Rate Limiting**: 60-second rolling window with auto-slowdown
- **Retry Strategy**: Exponential backoff (429: 5sâ†’10sâ†’20s, 5xx: 2sâ†’4sâ†’8s)
- **Proxy Support**: HTTP/SOCKS5 rotation on rate limits

### 3. Date Parsing Robustness
Implemented 5-tier fallback strategy:
1. Primary path: `el[2][2][0][1][21][6][8]` â†’ `[year, month, day]`
2. Alternative container search in first 5 elements
3. Fallback path: `el[2][21][6][8]`
4. Relative date: `el[2][1]` (e.g., "2 à¸ªà¸±à¸›à¸”à¸²à¸«à¹Œà¸—à¸µà¹ˆà¹à¸¥à¹‰à¸§")
5. Default: "Unknown Date"

### 4. Real-Time Progress Tracking
- **Server-Sent Events (SSE)**: Live updates every 1 second
- **Progress Callbacks**: Called after each page (20 reviews)
- **Visual Progress Bars**: Shows reviews/max with percentage
- **Unlimited Mode**: Auto-detects total_reviews from place data
- **Task Management**: Track multiple concurrent scraping tasks

### 5. UTF-8/Unicode Support
- Windows encoding fix: `chcp 65001` on startup
- Safe printing with ASCII fallback
- UTF-8 file encoding for JSON/CSV
- Thai character rendering in web UI

---

## ğŸš€ Deployment Ready

### What's Included

âœ… **Production-Ready Code**
- Clean, modular architecture
- Error handling and logging
- Performance optimizations
- Security best practices

âœ… **Complete Documentation**
- README.md (560+ lines)
- CLAUDE.md for developers (1000+ lines)
- CONTRIBUTING.md guidelines
- Code comments and docstrings

âœ… **Configuration Management**
- .env.example template
- Sensible defaults
- Easy customization

âœ… **Git Ready**
- .gitignore configured
- No sensitive data committed
- Clean commit history

âœ… **Testing**
- test_scraper.py for quick verification
- Example place IDs included
- Expected output documented

---

## ğŸ“¦ Dependencies

### Python Requirements

```txt
Flask==3.0.0
Flask-CORS==4.0.0
httpx==0.25.2
Werkzeug==3.0.1
```

**Total Dependencies**: 4 core packages (minimal footprint)

---

## ğŸŒŸ Unique Selling Points

1. **No API Key** - Completely free, no Google API limits
2. **High Performance** - 26-40+ reviews/sec (faster than competitors)
3. **Zero Duplicates** - Page token pagination ensures uniqueness
4. **Real-Time UI** - SSE streaming shows live progress
5. **Unlimited Mode** - Auto-detects and scrapes all reviews
6. **Thai Language** - Full UTF-8 support for Thai characters
7. **Production Ready** - Anti-bot protection, error handling, logging
8. **Open Source** - MIT License, community-driven

---

## ğŸ¯ Use Cases Supported

### 1. Business Intelligence
- **Competitor Analysis**: Compare reviews across multiple locations
- **Sentiment Analysis**: Extract Thai/English reviews for NLP
- **Market Research**: Identify customer pain points and preferences
- **Trend Analysis**: Track review volume and sentiment over time

### 2. Academic Research
- **Social Behavior**: Study location-based review patterns
- **Tourism Studies**: Analyze Chiang Mai culinary tourism
- **Data Science**: Train ML models on review data
- **Linguistic Analysis**: Study Thai-English code-switching

### 3. Data Collection
- **Training Data**: Collect reviews for ML/AI models
- **Database Population**: Build review databases
- **Historical Data**: Archive reviews with date filtering
- **Backup**: Create backups of business reviews

### 4. Monitoring
- **Reputation Management**: Track business reviews
- **Alert Systems**: Monitor new negative reviews
- **Performance Metrics**: Track rating changes over time
- **Competitor Tracking**: Monitor competitor review trends

---

## ğŸ›¡ï¸ Security & Ethics

### Security Measures
- âœ… No hardcoded credentials
- âœ… Environment variable configuration
- âœ… .gitignore prevents sensitive data commits
- âœ… Input validation and sanitization
- âœ… Safe file handling with path validation

### Ethical Considerations
- âš ï¸ **Educational Purpose**: Tool designed for research and learning
- âš ï¸ **Rate Limiting**: Built-in protection against server abuse
- âš ï¸ **Respects Google**: Doesn't overwhelm their infrastructure
- âš ï¸ **User Responsibility**: Users must comply with Terms of Service
- âš ï¸ **No Malicious Use**: Not intended for harmful activities

### Legal Disclaimer
- Provided for educational and research purposes only
- Users responsible for compliance with Google's ToS
- No warranty or liability for misuse
- Commercial use requires proper permissions

---

## ğŸ—ºï¸ Future Roadmap

### Planned Enhancements

**Performance:**
- [ ] Concurrent request processing (target: 50+ reviews/sec)
- [ ] Connection pooling optimization
- [ ] Response caching for repeat queries
- [ ] Batch place scraping optimization

**Features:**
- [ ] CAPTCHA solving integration (CapSolver)
- [ ] Photo downloading capability
- [ ] Review sentiment analysis (Thai/English)
- [ ] Email notifications on task completion
- [ ] Scheduled scraping (cron jobs)

**Infrastructure:**
- [ ] Docker containerization
- [ ] Redis-based task queue for distributed scraping
- [ ] RESTful API mode (no web UI required)
- [ ] Rate limit monitoring dashboard
- [ ] Elasticsearch integration for search

**UI/UX:**
- [ ] Dark mode support
- [ ] Mobile-responsive design improvements
- [ ] Real-time charts and visualizations
- [ ] Export to Excel format
- [ ] Batch export of multiple tasks

**Stealth:**
- [ ] Advanced fingerprinting (Canvas/WebGL)
- [ ] Residential proxy integration
- [ ] Browser automation fallback (Playwright)
- [ ] CAPTCHA auto-detection and handling

---

## ğŸ“Š Project Metrics

### Code Statistics
- **Total Lines of Code**: ~3,000+ lines
- **Documentation Lines**: ~2,500+ lines
- **Test Coverage**: Manual testing (automated tests planned)
- **Performance**: 26-40+ reviews/sec (7.5x improvement from initial)

### Development Time
- **Initial Development**: 8 hours (2025-11-10)
- **Web Application**: 6 hours (2025-11-11)
- **Documentation & Cleanup**: 2 hours (2025-11-11)
- **Total**: ~16 hours

### Files Managed
- **Source Files**: 15+ Python modules
- **Documentation**: 5 major docs
- **Archived Tests**: 30+ test scripts
- **Templates**: 8+ HTML files

---

## ğŸ™ Acknowledgments

### Inspiration
- Google Maps RPC API reverse engineering community
- Web scraping best practices from Scrapy and BeautifulSoup
- Flask web framework documentation
- Thai language processing resources

### Technologies Used
- **Python** - Core programming language
- **Flask** - Web application framework
- **httpx** - Modern async HTTP client
- **Tailwind CSS** - Utility-first CSS framework
- **Server-Sent Events** - Real-time updates

### Special Thanks
- Claude AI (Anthropic) - Development assistance
- Open source community - Libraries and tools
- Early testers - Feedback and bug reports

---

## ğŸ“ Support & Contact

### Getting Help
- **GitHub Issues**: Technical problems and bug reports
- **GitHub Discussions**: Questions, ideas, feature requests
- **Email**: your.email@example.com
- **Documentation**: README.md, CLAUDE.md

### Contributing
See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines on:
- Submitting pull requests
- Reporting bugs
- Requesting features
- Code style and standards

---

## ğŸ“„ License

This project is licensed under the **MIT License**.

```
Copyright (c) 2025 Nextzus

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software...
```

See [LICENSE](LICENSE) for full text.

---

## ğŸ‰ Conclusion

Google Maps RPC Scraper represents a complete, production-ready solution for extracting Google Maps reviews at scale. With comprehensive anti-bot protection, real-time progress tracking, and a modern web interface, it stands as a robust framework for data collection and analysis.

The project is fully documented, well-structured, and ready for community contributions. Whether you're a researcher, developer, or business owner, this tool provides the foundation for extracting valuable insights from Google Maps reviews.

**Ready to scrape? Star â­ the repo and get started!**

---

**Document Version:** 1.0.0
**Last Updated:** 2025-11-11
**Maintained by:** Nextzus
**Project Status:** âœ… Production Ready
